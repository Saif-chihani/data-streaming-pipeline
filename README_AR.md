# ูุธุงู ูุนุงูุฌุฉ ุจูุงูุงุช ุงูุชูุงุนู ูู ุงูููุช ุงููุนูู

ูุธุงู ุชุฏูู ุงูุจูุงูุงุช ูู ุงูููุช ุงููุนูู ููุนุงูุฌุฉ ุฃุญุฏุงุซ ุชูุงุนู ุงููุณุชุฎุฏููู ูู PostgreSQL ุฅูู BigQuery ู Redis ููุธุงู ุฎุงุฑุฌู ูุน ุชุญูููุงุช ูุฅุซุฑุงุกุงุช ุงูุจูุงูุงุช.

## ๐ฏ ุงููุฏู

ูููู ูุฐุง ุงููุดุฑูุน ุจุชูููุฐ ูุธุงู ุชุฏูู ุงูุจูุงูุงุช ุงูุฐู:

- **ููุชูุท** ุฃุญุฏุงุซ ุงูุชูุงุนู ูู ุงูููุช ุงููุนูู ูู PostgreSQL
- **ููุซุฑู** ุงูุจูุงูุงุช ุนุจุฑ ุฑุจุทูุง ุจุจูุงูุงุช ุชุนุฑูู ุงููุญุชูู
- **ููุญูู** ุงูุฃุญุฏุงุซ (ุญุณุงุจ ุงููุฏุฏุ ูุณุจ ุงูุชูุงุนู)
- **ููุฒุน** ุฅูู 3 ูุฌูุงุช ุจุงูุชูุงุฒู (Fan-out Multi-sink)
- **ูุถูู** ูุนุงูุฌุฉ exactly-once
- **ูููุฑ** ุชุฌููุนุงุช ุงูููุช ุงููุนูู (Redis < 5 ุซูุงูู)

## ๐๏ธ ุงููุนูุงุฑูุฉ

```
PostgreSQL (ุงููุตุฏุฑ) 
     โ (CDC)
   Kafka Topic
     โ
Stream Processor
     โ (Fan-out)
  โโโโโโโฌโโโโโโฌโโโโโโ
  โ     โ     โ     โ
Redis BigQuery External Monitoring
```

### ุงูููููุงุช

1. **PostgreSQL** : ูุงุนุฏุฉ ุงูุจูุงูุงุช ุงููุตุฏุฑ ูุน ุฌุฏุงูู `content` ู `engagement_events`
2. **Kafka** : ูุณูุท ุงูุฑุณุงุฆู ูุงูุชูุงุท ุชุบููุฑุงุช ุงูุจูุงูุงุช (CDC)
3. **Stream Processor** : ุชุทุจูู Python ุงูุฑุฆูุณู ูุน ูุนุงูุฌุฉ exactly-once
4. **Redis** : ุชุฌููุนุงุช ุงูููุช ุงููุนูู (< 5 ุซูุงูู)
5. **BigQuery** : ุงูุชุญูููุงุช ูุงูุชูุงุฑูุฑ
6. **ุงููุธุงู ุงูุฎุงุฑุฌู** : API REST ููุชูุงููุงุช ุงูุฎุงุฑุฌูุฉ
7. **ุงููุฑุงูุจุฉ** : API ููุตุญุฉ ูููุงููุณ Prometheus

## ๐ ูููุฐุฌ ุงูุจูุงูุงุช

### ุงููุตุฏุฑ (PostgreSQL)

```sql
-- ูุชุงููุฌ ุงููุญุชูู
CREATE TABLE content (
    id              UUID PRIMARY KEY,
    slug            TEXT UNIQUE NOT NULL,
    title           TEXT NOT NULL,
    content_type    TEXT CHECK (content_type IN ('podcast', 'newsletter', 'video')),
    length_seconds  INTEGER, 
    publish_ts      TIMESTAMPTZ NOT NULL
);

-- ุฃุญุฏุงุซ ุงูุชูุงุนู ุงูุฎุงู
CREATE TABLE engagement_events (
    id           BIGSERIAL PRIMARY KEY,
    content_id   UUID REFERENCES content(id),
    user_id      UUID,
    event_type   TEXT CHECK (event_type IN ('play', 'pause', 'finish', 'click')),
    event_ts     TIMESTAMPTZ NOT NULL,
    duration_ms  INTEGER,
    device       TEXT,
    raw_payload  JSONB
);
```

### ุงูุชุญูููุงุช

ููู ุญุฏุซุ ูุญุณุจ ุงููุธุงู:

- **engagement_seconds** = `duration_ms / 1000`
- **engagement_pct** = `(engagement_seconds / length_seconds) * 100`

## ๐ ุงูุชุซุจูุช ูุงูุชุดุบูู

### ุงููุชุทูุจุงุช ุงููุณุจูุฉ

- Docker & Docker Compose
- Python 3.11+
- ุฐุงูุฑุฉ ูุตูู ุนุดูุงุฆู 8GB ุนูู ุงูุฃูู
- ุงูููุงูุฐ ุงููุชุงุญุฉ: 5432, 6379, 9092, 8083, 8080

### ุงูุจุฏุก ุงูุณุฑูุน

1. **ุงุณุชูุณุงุฎ ูุชูููู ุงููุดุฑูุน**
```bash
git clone https://github.com/seifchihani/data-streaming-pipeline.git
cd data-streaming-pipeline
cp .env.example .env
```

2. **ุชุนุฏูู ุงูุชูููู**
```bash
# ูู ุจุชุญุฑูุฑ .env ูุน ูุนุงููุงุชู
nano .env
```

3. **ุชุดุบูู ุงูุจููุฉ ุงูุชุญุชูุฉ**
```bash
# Linux/Mac
chmod +x start.sh
./start.sh

# Windows
docker-compose up -d
```

4. **ุงูุชุญูู ูู ุงูุญุงูุฉ**
```bash
# ุตุญุฉ ุงูุฎุฏูุงุช
curl http://localhost:8080/health

# ุฃูุถู ูุญุชูู ูู ุงูููุช ุงููุนูู
curl http://localhost:8080/top-content
```

### ุงูุฃูุงูุฑ ุงููููุฏุฉ

```bash
# ุนุฑุถ ุงูุณุฌูุงุช
docker-compose logs -f stream-processor
docker-compose logs -f data-generator

# ุฅุนุงุฏุฉ ุชุดุบูู ุฎุฏูุฉ
docker-compose restart stream-processor

# ุฅููุงู ุฌููุน ุงูุฎุฏูุงุช
docker-compose down

# ุชูุธูู ุงูุฃุญุฌุงู (โ๏ธ ููุฏุงู ุงูุจูุงูุงุช)
docker-compose down -v
```

## โ๏ธ ุงูุชูููู

### ูุชุบูุฑุงุช ุงูุจูุฆุฉ ุงูุฑุฆูุณูุฉ

```bash
# ูุงุนุฏุฉ ุงูุจูุงูุงุช
DATABASE_URL=postgresql://postgres:postgres@localhost:5432/engagement_db

# Kafka
KAFKA_BOOTSTRAP_SERVERS=localhost:9092
KAFKA_TOPIC_ENGAGEMENT_EVENTS=engagement-events

# Redis
REDIS_URL=redis://localhost:6379
REDIS_AGGREGATION_WINDOW_MINUTES=10

# BigQuery
BIGQUERY_PROJECT_ID=your-project-id
BIGQUERY_DATASET_ID=engagement_analytics

# ุงููุนุงูุฌุฉ
BATCH_SIZE=100
PROCESSING_INTERVAL_SECONDS=1
ENABLE_EXACTLY_ONCE=true
```

### ุฅุนุฏุงุฏ BigQuery

1. ุฅูุดุงุก ูุดุฑูุน GCP
2. ุชูุนูู BigQuery API
3. ุฅูุดุงุก ููุชุงุญ ุฎุฏูุฉ
4. ุชุญููู ููู JSON ูู `config/bigquery-credentials.json`

## ๐ ุฃูุถุงุน ุงูุชุดุบูู

### ูุถุน ุงูุชุฏูู (ุงูููุช ุงููุนูู)

```bash
docker exec -it stream_processor python -m src.stream_processor --mode stream
```

### ูุถุน ุงูููุก ุงูุฎููู (ุงูุจูุงูุงุช ุงูุชุงุฑูุฎูุฉ)

```bash
docker exec -it stream_processor python -m src.stream_processor \
  --mode backfill \
  --start-date 2025-08-01 \
  --end-date 2025-08-10
```

### ุชูููุฏ ุงูุจูุงูุงุช

```bash
# ุงููุถุน ุงููุณุชูุฑ
docker exec -it data_generator python -m src.data_generator --mode continuous

# ุฏูุนุฉ ูุงุญุฏุฉ
docker exec -it data_generator python -m src.data_generator --mode batch --batch-size 100

# ุงูุจูุงูุงุช ุงูุชุงุฑูุฎูุฉ
docker exec -it data_generator python -m src.data_generator --mode historical --historical-days 7
```

## ๐ ุงููุฑุงูุจุฉ ูุงูููุงููุณ

### API ุงูุตุญุฉ

- **ุงูุตุญุฉ ุงูุนุงูุฉ** : `GET /health`
- **ููุงููุณ ุงููุธุงู** : `GET /metrics`
- **Prometheus** : `GET /metrics/prometheus`
- **ุฃูุถู ูุญุชูู** : `GET /top-content`
- **ุฅุญุตุงุฆูุงุช ุงููุญุชูู** : `GET /content/{id}/stats`

### Redis - ุจูุงูุงุช ุงูููุช ุงููุนูู

```python
# ุงููุญุชูู ุงูุฃูุซุฑ ุชูุงุนูุงู (ุขุฎุฑ 10 ุฏูุงุฆู)
top_content = await redis_sink.get_top_content(limit=10)

# ุงูุฅุญุตุงุฆูุงุช ุงูุฎุงุตุฉ ุจูุญุชูู ูุนูู
stats = await redis_sink.get_content_stats(content_id)

# ุงูุฃุญุฏุงุซ ุงูุฃุฎูุฑุฉ
events = await redis_sink.get_recent_events(content_id, count=50)
```

### BigQuery - ุงูุชุญูููุงุช

```sql
-- ุงูุนุฑุถ ุงููููู ููุชูุงุนู
SELECT * FROM `project.dataset.daily_engagement_summary`
WHERE event_date >= CURRENT_DATE() - 7;

-- ุงูุงุชุฌุงูุงุช ุจุงูุณุงุนุฉ
SELECT * FROM `project.dataset.hourly_engagement_trends`
WHERE hour_bucket >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 24 HOUR);
```

## ๐ง ุงูุชุทููุฑ

### ูููู ุงููุดุฑูุน

```
data-streaming-pipeline/
โโโ src/
โ   โโโ models.py              # ููุงุฐุฌ ุงูุจูุงูุงุช Pydantic
โ   โโโ config.py              # ุงูุชูููู ุงููุฑูุฒู
โ   โโโ data_generator.py      # ูููุฏ ุจูุงูุงุช ุงูุงุฎุชุจุงุฑ
โ   โโโ stream_processor.py    # ุงููุนุงูุฌ ุงูุฑุฆูุณู
โ   โโโ monitoring.py          # API ุงููุฑุงูุจุฉ
โ   โโโ sinks/
โ       โโโ redis_sink.py      # Redis sink
โ       โโโ bigquery_sink.py   # BigQuery sink
โ       โโโ external_sink.py   # ุงููุธุงู ุงูุฎุงุฑุฌู sink
โโโ sql/
โ   โโโ init.sql              # ุงููุฎุทุท ูุงูุจูุงูุงุช ุงูุฃูููุฉ
โโโ docker/
โ   โโโ Dockerfile.generator   # ุตูุฑุฉ ุงููููุฏ
โ   โโโ Dockerfile.processor   # ุตูุฑุฉ ุงููุนุงูุฌ
โโโ config/
โ   โโโ bigquery-credentials.json
โโโ docker-compose.yml
โโโ requirements.txt
โโโ README.md
```

### ุงูุงุฎุชุจุงุฑุงุช

```bash
# ุงุฎุชุจุงุฑุงุช ุงููุญุฏุฉ
docker exec -it stream_processor python -m pytest tests/

# ุงุฎุชุจุงุฑ ุงูุญูู
docker exec -it data_generator python -m src.data_generator \
  --mode batch --batch-size 1000
```

## ๐ฏ ุงูุฃุฏุงุก ูุงูุถูุงูุงุช

### ุฒูู ุงูุงุณุชุฌุงุจุฉ
- **Redis** : < 5 ุซูุงูู (ุงููุฏู ูุญูู)
- **BigQuery** : ุฏูุนุฉ 30 ุซุงููุฉ ูุญุฏ ุฃูุตู
- **ุงููุธุงู ุงูุฎุงุฑุฌู** : < 30 ุซุงููุฉ ูุน ุฅุนุงุฏุฉ ุงููุญุงููุฉ

### ุงูุฅูุชุงุฌูุฉ
- **ุงูุฅูุชุงุฌ** : 1000+ ุญุฏุซ/ุซุงููุฉ
- **ุงูููุก ุงูุฎููู** : 10,000+ ุญุฏุซ/ุซุงููุฉ

### ุงูุถูุงูุงุช
- **ูุนุงูุฌุฉ exactly-once** ูุน ูุนุงููุงุช Kafka
- **Idempotence** ุนูู ุฌููุน ุงููุตุงุฑู
- **ุฅุนุงุฏุฉ ุงููุญุงููุฉ ุงูุชููุงุฆูุฉ** ูุน backoff ุฃุณู
- **Dead letter queues** ููุฅุฎูุงูุงุช ุงููุณุชูุฑุฉ

## ๐ ุงุณุชูุดุงู ุงูุฃุฎุทุงุก

### ุงููุดุงูู ุงูุดุงุฆุนุฉ

1. **Kafka ูู ูุจุฏุฃ**
```bash
docker-compose logs kafka
# ุชุญูู ูู ุงูููุงูุฐ ู Zookeeper
```

2. **ุจูุงูุงุช ุงุนุชูุงุฏ BigQuery ููููุฏุฉ**
```bash
# ุชุญูู ูู ููู ุจูุงูุงุช ุงูุงุนุชูุงุฏ
ls -la config/bigquery-credentials.json
```

3. **ุฑูุถ ุงุชุตุงู Redis**
```bash
docker-compose logs redis
# ุชุญูู ูู ุชุดุบูู Redis
```

4. **ุงููุนุงูุฌ ูุชููู**
```bash
# ุณุฌูุงุช ููุตูุฉ
docker-compose logs -f stream-processor
# ุฅุนุงุฏุฉ ุชุดุบูู ุฅุฐุง ูุฒู ุงูุฃูุฑ
docker-compose restart stream-processor
```

## ๐ ุฎุงุฑุทุฉ ุงูุทุฑูู ูุงูุชุญุณููุงุช

### ููููุฐ โ
- [x] ุงูุชุฏูู ูู ุงูููุช ุงููุนูู ูุน Kafka
- [x] ูุนุงูุฌุฉ Exactly-once
- [x] Fan-out ุฅูู 3 ูุฌูุงุช
- [x] ุชุฌููุนุงุช Redis < 5 ุซูุงูู
- [x] ุงูููุก ุงูุฎููู ููุจูุงูุงุช ุงูุชุงุฑูุฎูุฉ
- [x] ุงููุฑุงูุจุฉ ูุงูููุงููุณ
- [x] ุญุงููุฉ Docker

### ุงูุฎุทูุงุช ุงูุชุงููุฉ ๐ง
- [ ] Schema Registry ูุชุทููุฑ ุงูุจูุงูุงุช
- [ ] Kafka Streams ูููุนุงูุฌุฉ ุงูููุฒุนุฉ
- [ ] ุงูุชูุณุน ุงูุชููุงุฆู ุนูู ุฃุณุงุณ ุงูุญูู
- [ ] ุงุฎุชุจุงุฑุงุช ุงูุชูุงูู end-to-end
- [ ] ููุญุงุช ูุนูููุงุช Grafana
- [ ] ุงูุชูุจูู ุงูุชููุงุฆู
- [ ] ุชุดููุฑ ุงูุจูุงูุงุช ุงูุญุณุงุณุฉ

## ๐ ุงููุณุชูุฏุน

```bash
git clone https://github.com/seifchihani/data-streaming-pipeline.git
```

**ุงูุฑุงุจุท**: [https://github.com/seifchihani/data-streaming-pipeline](https://github.com/seifchihani/data-streaming-pipeline)

## ๐ ุงูุชุฑุฎูุต

ูุฐุง ุงููุดุฑูุน ูุฑุฎุต ุชุญุช ุฑุฎุตุฉ MIT. ุงูุธุฑ ููู `LICENSE` ููุฒูุฏ ูู ุงูุชูุงุตูู.

## ๐จโ๐ป ุงููุทูุฑ

ุชู ุชุทููุฑู ูู ุฅุทุงุฑ ุงุฎุชุจุงุฑ ุชููู ูููุตุจ ูููุฏุณ ุจูุงูุงุช ุฃูู.

**ุงูุชูููุงุช ุงููุณุชุฎุฏูุฉ**: Python, Kafka, PostgreSQL, Redis, BigQuery, Docker, FastAPI, Pydantic

---

## Installation Guide | ุฏููู ุงูุชุซุจูุช

### English Instructions
1. Clone the repository: `git clone https://github.com/seifchihani/data-streaming-pipeline.git`
2. Navigate to project: `cd data-streaming-pipeline`
3. Start services: `docker-compose up -d`
4. Check health: `curl http://localhost:8080/health`

### ุงูุชุนูููุงุช ุจุงูุนุฑุจูุฉ
1. ุงุณุชูุณุงุฎ ุงููุณุชูุฏุน: `git clone https://github.com/seifchihani/data-streaming-pipeline.git`
2. ุงูุงูุชูุงู ูููุดุฑูุน: `cd data-streaming-pipeline`
3. ุชุดุบูู ุงูุฎุฏูุงุช: `docker-compose up -d`
4. ูุญุต ุงูุตุญุฉ: `curl http://localhost:8080/health`
