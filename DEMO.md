# ğŸ¬ Guide de DÃ©monstration Rapide

Ce guide vous permet de tester le pipeline en 5 minutes !

## ğŸš€ DÃ©marrage Ultra-Rapide

```bash
# 1. Cloner le projet
git clone https://github.com/seifchihani/data-streaming-pipeline.git
cd data-streaming-pipeline

# 2. Lancer tout d'un coup
docker-compose up -d

# 3. Attendre 30 secondes et tester
sleep 30
curl http://localhost:8080/health
```

## ğŸ“Š Endpoints de Test

Une fois le systÃ¨me dÃ©marrÃ©, testez ces endpoints :

### SantÃ© du SystÃ¨me
```bash
curl http://localhost:8080/health
```
**Attendu :** Status "healthy" pour tous les composants

### Top Contenu Temps RÃ©el
```bash
curl http://localhost:8080/top-content
```
**Attendu :** Liste des contenus les plus engageants des 10 derniÃ¨res minutes

### MÃ©triques SystÃ¨me
```bash
curl http://localhost:8080/metrics
```
**Attendu :** Statistiques de traitement en temps rÃ©el

### Stats d'un Contenu SpÃ©cifique
```bash
# RÃ©cupÃ©rer un content_id depuis top-content, puis :
curl http://localhost:8080/content/{CONTENT_ID}/stats
```

## ğŸ§ª Test de Performance

### GÃ©nÃ©rateur de Charge
```bash
# GÃ©nÃ©rer 1000 Ã©vÃ©nements d'un coup
docker exec -it data_generator python -m src.data_generator \
  --mode batch --batch-size 1000

# VÃ©rifier le traitement
curl http://localhost:8080/top-content
```

### VÃ©rification Redis (< 5 secondes)
```bash
# GÃ©nÃ©rer un Ã©vÃ©nement
docker exec -it data_generator python -m src.data_generator \
  --mode batch --batch-size 1

# ImmÃ©diatement aprÃ¨s, vÃ©rifier Redis
curl http://localhost:8080/top-content
# Les donnÃ©es doivent apparaÃ®tre en moins de 5 secondes âœ…
```

## ğŸ“ˆ Monitoring en Temps RÃ©el

### Logs des Composants
```bash
# Stream processor (composant principal)
docker-compose logs -f stream-processor

# GÃ©nÃ©rateur de donnÃ©es
docker-compose logs -f data-generator

# Tous les services
docker-compose logs -f
```

### Base de DonnÃ©es
```bash
# Se connecter Ã  PostgreSQL
docker exec -it postgres_source psql -U postgres -d engagement_db

# VÃ©rifier les donnÃ©es
SELECT COUNT(*) FROM engagement_events;
SELECT * FROM enriched_engagement_events LIMIT 5;
```

### Redis
```bash
# Se connecter Ã  Redis
docker exec -it redis_cache redis-cli

# VÃ©rifier les agrÃ©gations
ZREVRANGE top_content_last_10min 0 5 WITHSCORES
```

## ğŸ¯ DÃ©monstration des Features

### 1. Streaming Temps RÃ©el
```bash
# Terminal 1 : Surveiller les logs
docker-compose logs -f stream-processor

# Terminal 2 : GÃ©nÃ©rer des Ã©vÃ©nements continus
docker exec -it data_generator python -m src.data_generator --mode continuous

# Terminal 3 : Surveiller les rÃ©sultats
watch -n 2 "curl -s http://localhost:8080/top-content | jq '.top_content[0:3]'"
```

### 2. Backfill Historique
```bash
# Remplir 7 jours d'historique
docker exec -it stream_processor python -m src.stream_processor \
  --mode backfill \
  --start-date 2025-08-03 \
  --end-date 2025-08-10
```

### 3. Exactly-Once Processing
Les Ã©vÃ©nements sont traitÃ©s exactement une fois grÃ¢ce Ã  :
- Transactions Kafka avec commit manuel
- Idempotence sur tous les sinks
- Gestion des doublons automatique

## ğŸ”§ DÃ©pannage Express

### Services ne dÃ©marrent pas
```bash
docker-compose down -v
docker-compose up -d
docker-compose ps
```

### Erreur de connexion
```bash
# VÃ©rifier que tous les services sont healthy
docker-compose ps
# Attendre que tous montrent "healthy"
```

### Pas de donnÃ©es dans Redis
```bash
# VÃ©rifier le gÃ©nÃ©rateur
docker-compose logs data-generator

# VÃ©rifier le processeur
docker-compose logs stream-processor

# Forcer la gÃ©nÃ©ration
docker restart data_generator
```

## ğŸ† RÃ©sultats Attendus

AprÃ¨s 2-3 minutes de fonctionnement :

1. **Health Check** : Tous les composants "healthy"
2. **Top Content** : Liste mise Ã  jour en temps rÃ©el
3. **Latence Redis** : < 5 secondes âœ…
4. **DÃ©bit** : 100+ Ã©vÃ©nements/seconde traitÃ©s
5. **BigQuery** : DonnÃ©es enrichies stockÃ©es (si configurÃ©)

## ğŸ“‹ Checklist de Validation

- [ ] `curl http://localhost:8080/health` retourne "healthy"
- [ ] `curl http://localhost:8080/top-content` retourne des donnÃ©es
- [ ] Les logs montrent le traitement d'Ã©vÃ©nements
- [ ] Redis rÃ©pond en < 5 secondes
- [ ] Pas d'erreurs dans les logs
- [ ] Tous les containers sont "healthy"

---

**ğŸ‰ FÃ©licitations !** Votre pipeline de streaming fonctionne parfaitement !

Pour une dÃ©monstration complÃ¨te, voir [README.md](./README.md) et [README_AR.md](./README_AR.md)
